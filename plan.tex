\documentclass{article}
\usepackage[utf8]{inputenc}

\title{Project Plan \\ \large{Master Thesis Data Science}}

\author{S\'ebastiaan Versteeg, s4459636}
\date{August 2021}

\begin{document}

\maketitle

\section{General information}

Start date:\\
September 2021\\
\\
Expected end date:\\
February 2022\\
\\
Study programme:\\
Computing Science, specialisation Data Science\\
\\
Preliminary project title:\\
Anomaly detection using linear inpainting transformers\\

\section{Problem statement}
\label{problem-statement}

For this project we will focus on the task of anomaly detection using image inpainting. Anomaly detection is the task of detecting faults in a set of given images. 
This task is usually performed using convolutional autoencoders\cite{tsai_autoencoder-based_2021} or generative models\cite{xie_semisupervised_2021}.

In recent work the usage of transformers was introduced for computer vision tasks\cite{wu_visual_2020}. Transformers have also been used to explore anomaly detection\cite{pirnay_inpainting_2021}.

Transformers can require a lot of resources. Katharopoulos et al introduced linear transformers\cite{katharopoulos_transformers_2020} to improve the computational and memory costs. For our research we would like to explore using this type of transformers for anomaly detection.

\section{Approach}

We will start out project by trying to reproduce both the work into linear transformers and anomaly detection using inpainting mentioned in the previous section.
This will hopefully give us a solid starting point to try using the linear transformers for the task of anomaly detection. We hope to improve the efficiency, and if possible, performance for anomaly detection.

\section{Related work}

Previous work related to anomaly detection can be found using different approaches, like mentioned in the first section. But anomaly detection itself is also a diverse subject.

In 2018 Loganathan et al.\cite{loganathan_sequence_2018} presented their research using long short-term memory (LSTM) networks, a type of recurrent neural network (RNN). They applied this type of model on network packets to detect network intrusions.

In earlier work Erfani et al.\cite{erfani_high-dimensional_2016} used a type of support vector machines to make similar anomaly detections on IoT networks.

Like mentioned in the problem statement, another option is using autoencoders. Like Tsai et al.\cite{tsai_autoencoder-based_2021} did to look for surface defects.

Using generative adversarial networks (GAN) which was explored by both Zenati et al.\cite{zenati_efficient_2019} and Ngo et al.\cite{ngo_fence_2019} by looking at performance on the MNIST and KDD99 datasets.

Inpainting for anomaly detection has been explored already by Pirnay et al.\cite{pirnay_inpainting_2021} using transformers and Nguyen et al.\cite{adversarial-pirnay_inpainting_2021} using convolutional neural networks.

Inpainting has also been used in different contexts. Xie et al.\cite{xie_image_2012} utilised autoencoders and Yeh et al.\cite{yeh_semantic_2017} used GANs for this task, focusing on reconstructing images of faces. 

\section{Planning}

September, October:\\
Review existing literature, try to reproduce existing work. Write related work and background of paper.\\
\\
November, December:\\
Implement linear transformers for inpainting. Outline approach and experimental set-up in paper.\\
\\
January, February:\\
Collect comparable results for anomaly detection. Finish writing paper.


\bibliography{references} 
\bibliographystyle{acm}

\end{document}
